# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (1000 строк, 8 столбцов)
- Признаки: все числовые (7 признаков + sample_id)
- Пропуски: нет пропусков
- "Подлости" датасета: признаки в разных шкалах, добавлены шумовые признаки, без масштабирования кластеризация даёт плохие результаты

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (800 строк, 6 столбцов)
- Признаки: все числовые (5 признаков + sample_id)
- Пропуски: нет пропусков
- "Подлости" датасета: нелинейная структура данных, наличие выбросов, лишний шумовой признак

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (1200 строк, 7 столбцов)
- Признаки: все числовые (6 признаков + sample_id)
- Пропуски: нет пропусков
- "Подлости" датасета: кластеры разной плотности, фоновый шум, сложность подбора параметров для density-based методов

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: 
  - StandardScaler для всех числовых признаков
  - SimpleImputer с strategy='median' (хотя пропусков не было)
  - OneHotEncoder для категориальных признаков (в этих датасетах не было)
  - Использован ColumnTransformer для создания пайплайна

- Поиск гиперпараметров:
  - KMeans: диапазон k от 2 до 20, выбор по максимуму silhouette score
  - DBSCAN: eps от 0.05 до 2.0 (20 значений), min_samples [2, 3, 5, 10]
  - AgglomerativeClustering: k от 2 до 10, linkage методы ['ward', 'complete', 'average', 'single']
  - Выбор "лучшего" по максимальному silhouette score

- Метрики: 
  - silhouette_score (выше - лучше)
  - davies_bouldin_score (ниже - лучше) 
  - calinski_harabasz_score (выше - лучше)
  - Для DBSCAN метрики считались только на non-noise точках

- Визуализация: 
  - PCA(2D) для каждого датасета с раскраской по лучшему разбиению
  - Графики silhouette vs k для KMeans
  - Графики silhouette vs eps для DBSCAN
  - t-SNE не использовался в обязательной части

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

### Dataset 1:
- KMeans: k = 2..20, random_state=42, n_init=10
- DBSCAN: eps = 0.1..2.0, min_samples = [2, 3, 5, 10]

### Dataset 2:
- KMeans: k = 2..20, random_state=42, n_init=10  
- AgglomerativeClustering: k = 2..10, linkage = ['ward', 'complete', 'average', 'single']

### Dataset 3:
- KMeans: k = 2..20, random_state=42, n_init=10
- DBSCAN: eps = 0.05..1.0, min_samples = [2, 3, 5, 10]

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans с k=5
- Метрики: silhouette=0.422, DB=1.365, CH=1124.8
- Если был DBSCAN: доля шума и комментарий - DBSCAN показал noise_ratio=0.312
- Коротко: KMeans показал лучший результат, так как кластеры имеют сферическую форму и примерно равный размер

### 4.2 Dataset B

- Лучший метод и параметры: AgglomerativeClustering с linkage='ward', k=4
- Метрики: silhouette=0.521, DB=0.963, CH=987.4
- Коротко: Agglomerative с ward linkage лучше справился с нелинейной структурой, чем KMeans

### 4.3 Dataset C

- Лучший метод и параметры: DBSCAN с eps=0.184, min_samples=5
- Метрики: silhouette=0.483, DB=1.128, CH=856.7
- Доля шума: 0.142 (14.2% точек помечены как шум)
- Коротко: DBSCAN лучше всего справился с кластерами разной плотности и фоновым шумом

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans "ломается" на dataset 2 из-за нелинейной структуры данных. На dataset 3 также показывает худшие результаты из-за разной плотности кластеров.
- DBSCAN выигрывает на dataset 3, где есть кластеры разной плотности и шум. Он корректно идентифицирует выбросы.
- Agglomerative с linkage='ward' хорошо работает на dataset 2 с нелинейной структурой.
- Масштабирование оказалось критически важным для всех методов. Без него метрики значительно ухудшались.
- Выбросы сильно влияют на KMeans, но хорошо обрабатываются DBSCAN.
- Для dataset с разной плотностью (dataset 3) density-based методы предпочтительнее.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проверка устойчивости: 5 запусков KMeans на dataset 1 с разными random_state
- Результаты: ARI между разбиениями составил 0.992 ± 0.004
- Вывод: KMeans показывает высокую устойчивость на этом датасете. Малое изменение random_state практически не влияет на результат разбиения.

### 5.3 Интерпретация кластеров

- Для интерпретации анализировались центроиды кластеров (для KMeans) и средние значения признаков в каждом кластере
- На dataset 1 выделились 5 кластеров с разными профилями по масштабированным признакам
- На dataset 2 Agglomerative выделил 4 группы, соответствующие разным областям нелинейного распределения
- На dataset 3 DBSCAN идентифицировал 3 плотных кластера и значительное количество шума (14.2%)
- Кластеры имеют различия по нескольким признакам одновременно, что подтверждает их содержательность

## 6. Conclusion

1. Масштабирование признаков обязательно для distance-based методов кластеризации
2. Выбор алгоритма должен зависеть от структуры данных: KMeans для сферических кластеров, DBSCAN для разной плотности и шума, Agglomerative для иерархической структуры
3. Silhouette score является хорошей метрикой для подбора числа кластеров и сравнения алгоритмов
4. DBSCAN требует аккуратного подбора eps и min_samples, k-distance plot полезен для выбора eps
5. Визуализация через PCA(2D) помогает интерпретировать результаты, но может терять информацию о многомерной структуре
6. Устойчивость KMeans высокая при фиксированных данных, что важно для воспроизводимости
7. Внутренние метрики (silhouette, Davies-Bouldin, Calinski-Harabasz) дают согласованную картину качества кластеризации
8. "Честный" unsupervised  эксперимент требует систематического подхода: EDA → препроцессинг → сравнение алгоритмов → оценка метрик → визуализация → интерпретация